{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb41731",
   "metadata": {},
   "source": [
    "### Tools calling example with Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e12f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63bdf783",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b542b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use arxiv to find the papers \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "    \n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info  \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "    \n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "    \n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "    \n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2004ba75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers/machine_learning/papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1909.03550v1', '1811.04422v1', '1707.04849v1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"machine learning\", max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52354a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    " \n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6a9f635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"Lecture Notes: Optimization for Machine Learning\",\n",
      "  \"authors\": [\n",
      "    \"Elad Hazan\"\n",
      "  ],\n",
      "  \"summary\": \"Lecture notes on optimization for machine learning, derived from a course at\\nPrinceton University and tutorials given in MLSS, Buenos Aires, as well as\\nSimons Foundation, Berkeley.\",\n",
      "  \"pdf_url\": \"http://arxiv.org/pdf/1909.03550v1\",\n",
      "  \"published\": \"2019-09-08\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "info = extract_info('1909.03550v1')\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c57132",
   "metadata": {},
   "source": [
    "### Tool Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "721d0133",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"search_papers\",\n",
    "        \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The topic to search for\"\n",
    "                }, \n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Maximum number of results to retrieve\",\n",
    "                    \"default\": 5\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"topic\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"extract_info\",\n",
    "        \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"paper_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ID of the paper to look for\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"paper_id\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "069ecf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name, tool_args):\n",
    "    print(\"#\"*30)\n",
    "    print(f\"Executing tool: {tool_name} with arguments: {tool_args}\")\n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "    print(\"#\"*30)\n",
    "    \n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "\n",
    "    if result is None:\n",
    "        result = \"The operation completed but didn't return any results.\"\n",
    "        \n",
    "    elif isinstance(result, list):\n",
    "        result = ', '.join(result)\n",
    "        \n",
    "    elif isinstance(result, dict):\n",
    "        # Convert dictionaries to formatted JSON strings\n",
    "        result = json.dumps(result, indent=2)\n",
    "    \n",
    "    else:\n",
    "        # For any other type, convert using str()\n",
    "        result = str(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88905d70",
   "metadata": {},
   "source": [
    "### Chatbot Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "494d1f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "client = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5febc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    \n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "    response = client.messages.create(max_tokens = 2024,\n",
    "                                  model = 'claude-3-7-sonnet-20250219', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages)\n",
    "    \n",
    "    process_query = True\n",
    "    while process_query:\n",
    "        assistant_content = []\n",
    "\n",
    "        for content in response.content:\n",
    "            if content.type == 'text':\n",
    "                \n",
    "                print(content.text)\n",
    "                assistant_content.append(content)\n",
    "                \n",
    "                if len(response.content) == 1:\n",
    "                    process_query = False\n",
    "            \n",
    "            elif content.type == 'tool_use':\n",
    "                \n",
    "                assistant_content.append(content)\n",
    "                messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "                \n",
    "                tool_id = content.id\n",
    "                tool_args = content.input\n",
    "                tool_name = content.name\n",
    "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "                messages.append({\"role\": \"user\", \n",
    "                                  \"content\": [\n",
    "                                      {\n",
    "                                          \"type\": \"tool_result\",\n",
    "                                          \"tool_use_id\": tool_id,\n",
    "                                          \"content\": result\n",
    "                                      }\n",
    "                                  ]\n",
    "                                })\n",
    "                response = client.messages.create(max_tokens = 2024,\n",
    "                                  model = 'claude-3-7-sonnet-20250219', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages) \n",
    "                \n",
    "                if len(response.content) == 1 and response.content[0].type == \"text\":\n",
    "                    print(response.content[0].text)\n",
    "                    process_query = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "211af1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5e1cbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n",
      "MLOps (Machine Learning Operations) is an important topic in the field of artificial intelligence and machine learning. To provide you with up-to-date information, let me search for some recent papers on this subject.\n",
      "Calling tool search_papers with args {'topic': 'MLOps', 'max_results': 5}\n",
      "##############################\n",
      "Executing tool: search_papers with arguments: {'topic': 'MLOps', 'max_results': 5}\n",
      "Results are saved in: papers/mlops/papers_info.json\n",
      "##############################\n",
      "Results are saved in: papers/mlops/papers_info.json\n",
      "Let me get more detailed information about these papers to better explain MLOps to you:\n",
      "Calling tool extract_info with args {'paper_id': '2503.15577v1'}\n",
      "##############################\n",
      "Executing tool: extract_info with arguments: {'paper_id': '2503.15577v1'}\n",
      "##############################\n",
      "Calling tool extract_info with args {'paper_id': '2406.19847v1'}\n",
      "##############################\n",
      "Executing tool: extract_info with arguments: {'paper_id': '2406.19847v1'}\n",
      "##############################\n",
      "Calling tool extract_info with args {'paper_id': '2304.03254v1'}\n",
      "##############################\n",
      "Executing tool: extract_info with arguments: {'paper_id': '2304.03254v1'}\n",
      "##############################\n",
      "Calling tool extract_info with args {'paper_id': '2307.13473v1'}\n",
      "##############################\n",
      "Executing tool: extract_info with arguments: {'paper_id': '2307.13473v1'}\n",
      "##############################\n",
      "Calling tool extract_info with args {'paper_id': '2406.09737v2'}\n",
      "##############################\n",
      "Executing tool: extract_info with arguments: {'paper_id': '2406.09737v2'}\n",
      "##############################\n",
      "# MLOps: Machine Learning Operations\n",
      "\n",
      "Based on the research papers I've analyzed, here's a comprehensive explanation of MLOps:\n",
      "\n",
      "## What is MLOps?\n",
      "\n",
      "MLOps (Machine Learning Operations) is a set of practices, tools, and frameworks that aim to streamline and automate the process of deploying, monitoring, and maintaining machine learning models in production environments. It's essentially the application of DevOps principles to machine learning systems.\n",
      "\n",
      "## Key Components and Aspects of MLOps:\n",
      "\n",
      "1. **Lifecycle Framework**: MLOps encompasses the entire machine learning lifecycle, including:\n",
      "   - Problem definition\n",
      "   - Data acquisition and preparation\n",
      "   - Model development and training\n",
      "   - Model deployment\n",
      "   - Monitoring and management\n",
      "   - Governance and compliance\n",
      "\n",
      "2. **Architecture Components**: According to recent research, MLOps architectures typically include 35 different components that work together to support the implementation of machine learning systems in production.\n",
      "\n",
      "3. **Maturity Levels**: Organizations adopt MLOps at different maturity levels, with corresponding requirements for tools, roles, and resources at each level.\n",
      "\n",
      "4. **Tooling Ecosystem**: Numerous tools support different phases of the MLOps lifecycle. Research has identified at least 84 different MLOps tools that can be mapped to various DevOps phases.\n",
      "\n",
      "5. **Integration with LLMOps**: Recent developments have expanded MLOps to include Large Language Model Operations (LLMOps), addressing the specific challenges of deploying and managing large language models.\n",
      "\n",
      "## Challenges and Considerations:\n",
      "\n",
      "1. **Iterative Nature**: MLOps is highly iterative, with teams frequently revisiting earlier phases as new insights emerge or as models perform differently in production than expected.\n",
      "\n",
      "2. **Interdependencies**: The various phases of MLOps are deeply interconnected, requiring careful coordination.\n",
      "\n",
      "3. **Adoption Challenges**: Organizations face numerous socio-technical challenges when implementing MLOps, including integrating ML models with traditional software, continuous monitoring, maintenance, and retraining of deployed models.\n",
      "\n",
      "4. **Standardization Issues**: Different MLOps lifecycle frameworks and maturity models proposed by industry, academia, and organizations have led to confusion regarding standard adoption practices.\n",
      "\n",
      "MLOps has become increasingly important as organizations seek to move beyond proof-of-concept machine learning projects to reliable, production-ready AI systems that can deliver consistent business value. It addresses the reality that deploying models to production involves much more than just model development and requires systematic approaches to ensure reliability, scalability, and maintainability.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc021c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ths_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
