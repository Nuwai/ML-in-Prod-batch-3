{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb41731",
   "metadata": {},
   "source": [
    "### Tools calling example with Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e12f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63bdf783",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b542b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use arxiv to find the papers \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "    \n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info  \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "    \n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "    \n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "    \n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2004ba75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers/machine_learning/papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1909.03550v1', '1811.04422v1', '1707.04849v1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"machine learning\", max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52354a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    " \n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6a9f635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"Lecture Notes: Optimization for Machine Learning\",\n",
      "  \"authors\": [\n",
      "    \"Elad Hazan\"\n",
      "  ],\n",
      "  \"summary\": \"Lecture notes on optimization for machine learning, derived from a course at\\nPrinceton University and tutorials given in MLSS, Buenos Aires, as well as\\nSimons Foundation, Berkeley.\",\n",
      "  \"pdf_url\": \"http://arxiv.org/pdf/1909.03550v1\",\n",
      "  \"published\": \"2019-09-08\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "info = extract_info('1909.03550v1')\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c57132",
   "metadata": {},
   "source": [
    "### Tool Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "721d0133",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"search_papers\",\n",
    "        \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The topic to search for\"\n",
    "                }, \n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Maximum number of results to retrieve\",\n",
    "                    \"default\": 5\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"topic\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"extract_info\",\n",
    "        \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"paper_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ID of the paper to look for\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"paper_id\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "069ecf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name, tool_args):\n",
    "    \n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "\n",
    "    if result is None:\n",
    "        result = \"The operation completed but didn't return any results.\"\n",
    "        \n",
    "    elif isinstance(result, list):\n",
    "        result = ', '.join(result)\n",
    "        \n",
    "    elif isinstance(result, dict):\n",
    "        # Convert dictionaries to formatted JSON strings\n",
    "        result = json.dumps(result, indent=2)\n",
    "    \n",
    "    else:\n",
    "        # For any other type, convert using str()\n",
    "        result = str(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88905d70",
   "metadata": {},
   "source": [
    "### Chatbot Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "494d1f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "client = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5febc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    \n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "    response = client.messages.create(max_tokens = 2024,\n",
    "                                  model = 'claude-3-7-sonnet-20250219', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages)\n",
    "    \n",
    "    process_query = True\n",
    "    while process_query:\n",
    "        assistant_content = []\n",
    "\n",
    "        for content in response.content:\n",
    "            if content.type == 'text':\n",
    "                \n",
    "                print(content.text)\n",
    "                assistant_content.append(content)\n",
    "                \n",
    "                if len(response.content) == 1:\n",
    "                    process_query = False\n",
    "            \n",
    "            elif content.type == 'tool_use':\n",
    "                \n",
    "                assistant_content.append(content)\n",
    "                messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "                \n",
    "                tool_id = content.id\n",
    "                tool_args = content.input\n",
    "                tool_name = content.name\n",
    "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "                messages.append({\"role\": \"user\", \n",
    "                                  \"content\": [\n",
    "                                      {\n",
    "                                          \"type\": \"tool_result\",\n",
    "                                          \"tool_use_id\": tool_id,\n",
    "                                          \"content\": result\n",
    "                                      }\n",
    "                                  ]\n",
    "                                })\n",
    "                response = client.messages.create(max_tokens = 2024,\n",
    "                                  model = 'claude-3-7-sonnet-20250219', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages) \n",
    "                \n",
    "                if len(response.content) == 1 and response.content[0].type == \"text\":\n",
    "                    print(response.content[0].text)\n",
    "                    process_query = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "211af1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1cbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n",
      "\n",
      "Error: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.0: all messages must have non-empty content except for the optional final assistant message'}, 'request_id': 'req_011CT4C86xeSfU9DkZY3deup'}\n",
      "I'd be happy to help you find information about MLOps. MLOps (Machine Learning Operations) is an important area that combines machine learning systems with DevOps practices. Let me search for some recent papers on this topic to provide you with useful information.\n",
      "Calling tool search_papers with args {'topic': 'MLOps', 'max_results': 5}\n",
      "Results are saved in: papers/mlops/papers_info.json\n",
      "Great! I've found several papers about MLOps. Let me gather detailed information about each one to provide you with a comprehensive overview of recent research in this field.\n",
      "Calling tool extract_info with args {'paper_id': '2503.15577v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2406.19847v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2406.09737v2'}\n",
      "Calling tool extract_info with args {'paper_id': '2304.03254v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2307.13473v1'}\n",
      "# MLOps: An Overview of Recent Research\n",
      "\n",
      "Based on the papers I've found, here's a comprehensive overview of MLOps:\n",
      "\n",
      "## What is MLOps?\n",
      "\n",
      "MLOps (Machine Learning Operations) is a practice that combines machine learning systems with DevOps principles to automate and streamline the lifecycle of machine learning models from development to deployment and maintenance in production environments.\n",
      "\n",
      "## Key Research Areas in MLOps\n",
      "\n",
      "### 1. MLOps Frameworks and Maturity Models\n",
      "\n",
      "According to the paper \"Navigating MLOps: Insights into Maturity, Lifecycle, Tools, and Careers\" (March 2025), there are differing MLOps lifecycle frameworks and maturity models proposed by industry, academia, and organizations. This has led to confusion regarding standard adoption practices. The authors introduce a unified MLOps lifecycle framework that also incorporates Large Language Model Operations (LLMOps). The framework outlines key roles, tools, and costs associated with MLOps adoption at various maturity levels.\n",
      "\n",
      "### 2. MLOps Architectures\n",
      "\n",
      "The paper \"An Analysis of MLOps Architectures: A Systematic Mapping Study\" (June 2024) provides a comprehensive overview of how MLOps architectures are defined across literature and which tools support each architecture component. The study identifies:\n",
      "- 35 MLOps architecture components\n",
      "- Several MLOps architecture variants\n",
      "- A systematic map between identified components and existing MLOps tools\n",
      "\n",
      "This architectural perspective helps inform the design of MLOps systems for researchers and practitioners.\n",
      "\n",
      "### 3. MLOps Practices, Challenges, and Solutions\n",
      "\n",
      "\"A Multivocal Review of MLOps Practices, Challenges and Open Issues\" (June 2024) analyzed 150 peer-reviewed and 48 grey literature sources to develop a unified conceptualization of MLOps. The paper synthesizes best practices, adoption challenges, and solutions, addressing the socio-technical challenges of bringing ML models to production.\n",
      "\n",
      "### 4. MLOps Tools Landscape\n",
      "\n",
      "\"Toward End-to-End MLOps Tools Map: A Preliminary Study\" (April 2023) mapped 84 MLOps tools identified from 254 primary studies to different DevOps phases. This mapping highlights each tool's purpose and possible incompatibilities, providing practitioners and researchers with guidance on selecting appropriate tools for each phase of the MLOps process.\n",
      "\n",
      "### 5. MLOps Dynamics in Real-World Projects\n",
      "\n",
      "\"Exploring MLOps Dynamics: An Experimental Analysis in a Real-World Machine Learning Project\" (July 2023) presents an experiment focused on optimizing the MLOps process in a real-world setting. The study documented the iterative and interdependent nature of MLOps workflows, capturing revisits between phases and their reasons. The research offers practical tips and recommendations, emphasizing proactive planning and continuous improvement.\n",
      "\n",
      "## Key MLOps Components and Phases\n",
      "\n",
      "Based on these papers, the MLOps lifecycle typically includes:\n",
      "\n",
      "1. Problem definition\n",
      "2. Data acquisition and management\n",
      "3. Data preparation and feature engineering\n",
      "4. Model development and training\n",
      "5. Model evaluation and validation\n",
      "6. Model deployment\n",
      "7. Monitoring and maintenance\n",
      "8. Governance and compliance\n",
      "9. Scalability and infrastructure management\n",
      "\n",
      "## MLOps Benefits\n",
      "\n",
      "- Enables automation and reliable model deployments across industries\n",
      "- Addresses challenges of integrating ML models with non-ML software\n",
      "- Facilitates continuous monitoring, maintenance, and retraining of deployed models\n",
      "- Enhances efficiency and effectiveness of machine learning projects\n",
      "- Provides structured approaches to scaling ML initiatives\n",
      "\n",
      "This overview represents the current state of research in MLOps as reflected in recent academic publications. The field continues to evolve rapidly with new tools, frameworks, and best practices emerging regularly.\n",
      "\n",
      "\n",
      "I'd be happy to search for information about cloud native applications. This is a topic that has significant research in the computing and software engineering fields. Let me search for some recent papers on this topic to provide you with an up-to-date understanding.\n",
      "Calling tool search_papers with args {'topic': 'cloud native applications', 'max_results': 5}\n",
      "Results are saved in: papers/cloud_native_applications/papers_info.json\n",
      "Now, let me get more information about these papers to provide you with insights about cloud native applications.\n",
      "Calling tool extract_info with args {'paper_id': '1802.03562v1'}\n",
      "Calling tool extract_info with args {'paper_id': '1709.04883v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2306.14402v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2307.08530v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2408.15445v1'}\n",
      "Based on the research papers I've reviewed, I can provide you with a comprehensive understanding of cloud native applications:\n",
      "\n",
      "# Cloud Native Applications\n",
      "\n",
      "Cloud native applications are software applications specifically designed and built to take full advantage of cloud computing platforms and environments. They are fundamentally different from traditional applications that were simply migrated to the cloud (\"lift and shift\").\n",
      "\n",
      "## Key Characteristics\n",
      "\n",
      "1. **Designed for Cloud Platforms**: Cloud native applications are intentionally created to leverage cloud features like horizontal scaling, elasticity, and distributed architectures.\n",
      "\n",
      "2. **Microservices Architecture**: These applications are typically built as a collection of small, independent services rather than as monolithic applications.\n",
      "\n",
      "3. **Containerization**: Cloud native apps are packaged in containers (like Docker) that can run consistently across different environments.\n",
      "\n",
      "4. **Orchestration**: They rely on container orchestration platforms like Kubernetes, Docker Swarm, or Apache Mesos to manage deployment, scaling, and operations.\n",
      "\n",
      "5. **Elasticity**: Cloud native applications can automatically scale resources up or down based on demand.\n",
      "\n",
      "## Benefits\n",
      "\n",
      "- **Scalability**: Can easily handle varying workloads by scaling horizontally\n",
      "- **Resilience**: Built to be fault-tolerant and self-healing\n",
      "- **Portability**: Can run consistently across different cloud environments\n",
      "- **Agility**: Enables faster development and deployment cycles\n",
      "- **Cost-efficiency**: Resources can be scaled according to actual needs\n",
      "\n",
      "## Challenges\n",
      "\n",
      "1. **Vendor Lock-in**: As noted in several papers, cloud native applications can be vulnerable to vendor lock-in when using proprietary cloud services.\n",
      "\n",
      "2. **Complexity**: The distributed nature and container orchestration add complexity to development and operations.\n",
      "\n",
      "3. **Multi-cloud Deployment**: Deploying across multiple cloud providers remains challenging, though standardization efforts are ongoing.\n",
      "\n",
      "## Implementation Approaches\n",
      "\n",
      "Research indicates several approaches to building cloud native applications:\n",
      "\n",
      "1. **Using standardized IaaS services**: As suggested in the ClouNS reference model, focusing on well-standardized Infrastructure as a Service components can reduce vendor lock-in.\n",
      "\n",
      "2. **Domain-specific languages (DSLs)**: Some researchers propose lightweight DSLs to define cloud native applications in a way that makes them transferable between different cloud providers.\n",
      "\n",
      "3. **Cloud-native platforms**: Using technologies like Kubernetes as the foundation for deployments across different cloud environments.\n",
      "\n",
      "The cloud native approach continues to evolve, with ongoing research in areas like scientific workflow management, specialized cloud-native applications (like satellites), and performance optimization techniques like worker-pools for specific workloads.\n",
      "\n",
      "\n",
      "\n",
      "Error: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.0: all messages must have non-empty content except for the optional final assistant message'}, 'request_id': 'req_011CT4Cmdt2jXeNpDWXNZ5yh'}\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc021c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ths_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
